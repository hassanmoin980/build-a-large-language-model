{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8c67c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca36dfc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.0+cu130\n",
      "13.0\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Check PyTorch version and CUDA availability\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993c3d86",
   "metadata": {},
   "source": [
    "# A.2 Understanding Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692c6cbe",
   "metadata": {},
   "source": [
    "## A.2.1 Scalars, vectores, matrices, and tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a45297d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-D tensor (scalar) from a Python integer: 1, having shape torch.Size([]), dimension = 0\n",
      "1-D tensor (vector) from a Python list: tensor([1, 2, 3]), having shape torch.Size([3]), dimension = 1\n",
      "2-D tensor from a nested Python list: tensor([[1, 2],\n",
      "        [3, 4]]), having shape torch.Size([2, 2]), dimension = 2\n",
      "3-D tensor from a nested Python list: tensor([[[1, 2],\n",
      "         [3, 4]],\n",
      "\n",
      "        [[5, 6],\n",
      "         [7, 8]]]), having shape torch.Size([2, 2, 2]), dimension = 3\n",
      "4-D tensor from a nested Python list: tensor([[[[1, 2, 9, 9],\n",
      "          [3, 4, 9, 9]],\n",
      "\n",
      "         [[5, 6, 9, 9],\n",
      "          [7, 8, 9, 9]],\n",
      "\n",
      "         [[5, 6, 9, 9],\n",
      "          [7, 8, 9, 9]]],\n",
      "\n",
      "\n",
      "        [[[1, 2, 9, 9],\n",
      "          [3, 4, 9, 9]],\n",
      "\n",
      "         [[5, 6, 9, 9],\n",
      "          [7, 8, 9, 9]],\n",
      "\n",
      "         [[5, 6, 9, 9],\n",
      "          [7, 8, 9, 9]]],\n",
      "\n",
      "\n",
      "        [[[1, 2, 9, 9],\n",
      "          [3, 4, 9, 9]],\n",
      "\n",
      "         [[5, 6, 9, 9],\n",
      "          [7, 8, 9, 9]],\n",
      "\n",
      "         [[5, 6, 9, 9],\n",
      "          [7, 8, 9, 9]]]]), having shape torch.Size([3, 3, 2, 4]), dimension = 4\n"
     ]
    }
   ],
   "source": [
    "# To create a 0-D, 1-D, 2-D, and 3-D tensor in PyTorch:\n",
    "tensor0d = torch.tensor(1)\n",
    "tensor1d = torch.tensor([1, 2, 3])\n",
    "tensor2d = torch.tensor([[1, 2], [3, 4]])\n",
    "tensor3d = torch.tensor([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n",
    "tensor4d = torch.tensor(\n",
    "    [\n",
    "        [\n",
    "            [[1, 2, 9, 9], [3, 4, 9, 9]],\n",
    "            [[5, 6, 9, 9], [7, 8, 9, 9]],\n",
    "            [[5, 6, 9, 9], [7, 8, 9, 9]],\n",
    "        ],\n",
    "        [\n",
    "            [[1, 2, 9, 9], [3, 4, 9, 9]],\n",
    "            [[5, 6, 9, 9], [7, 8, 9, 9]],\n",
    "            [[5, 6, 9, 9], [7, 8, 9, 9]],\n",
    "        ],\n",
    "        [\n",
    "            [[1, 2, 9, 9], [3, 4, 9, 9]],\n",
    "            [[5, 6, 9, 9], [7, 8, 9, 9]],\n",
    "            [[5, 6, 9, 9], [7, 8, 9, 9]],\n",
    "        ],\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"0-D tensor (scalar) from a Python integer: {tensor0d}, having shape {tensor0d.size()}, dimension = {tensor0d.dim()}\"\n",
    ")\n",
    "print(\n",
    "    f\"1-D tensor (vector) from a Python list: {tensor1d}, having shape {tensor1d.size()}, dimension = {tensor1d.dim()}\"\n",
    ")\n",
    "print(\n",
    "    f\"2-D tensor from a nested Python list: {tensor2d}, having shape {tensor2d.size()}, dimension = {tensor2d.dim()}\"\n",
    ")\n",
    "print(\n",
    "    f\"3-D tensor from a nested Python list: {tensor3d}, having shape {tensor3d.size()}, dimension = {tensor3d.dim()}\"\n",
    ")\n",
    "print(\n",
    "    f\"4-D tensor from a nested Python list: {tensor4d}, having shape {tensor4d.size()}, dimension = {tensor4d.dim()}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d6c704",
   "metadata": {},
   "source": [
    "## A.2.2 Tensor data types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169fb01b",
   "metadata": {},
   "source": [
    "#### By default, python *integers* create tensors of dtype torch.int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c89ca713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n",
      "torch.int64\n",
      "torch.int64\n",
      "torch.int64\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "print(tensor0d.dtype)\n",
    "print(tensor1d.dtype)\n",
    "print(tensor2d.dtype)\n",
    "print(tensor3d.dtype)\n",
    "print(tensor4d.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fe2db8",
   "metadata": {},
   "source": [
    "#### By default, python *floats* create tensors of dtype torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f557554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "tensor1d_float = torch.tensor([1.0, 2.0, 3.0])\n",
    "print(tensor1d_float.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3685b7",
   "metadata": {},
   "source": [
    "> **Note**: GPU architectures are optimized for 32-bit computations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d36b2fd",
   "metadata": {},
   "source": [
    "#### To change a tensor's dtype, use the .to() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ee0bd39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float64\n"
     ]
    }
   ],
   "source": [
    "tensor1d_float64 = tensor1d_float.to(torch.float64)\n",
    "print(tensor1d_float64.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2659b13b",
   "metadata": {},
   "source": [
    "## A.2.3 Common PyTorch tensor operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7035c3",
   "metadata": {},
   "source": [
    "#### Create new tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6d1bc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor2d = torch.tensor([[1, 2], [3, 4]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b68d941",
   "metadata": {},
   "source": [
    "#### Reshape tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8539222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "print(tensor2d)\n",
    "print(tensor2d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "107d47b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]])\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor2d.reshape(4, 1))\n",
    "print(tensor2d.view(4, 1))  # Both are similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5932ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 3],\n",
      "        [2, 4]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor2d.T)  # Transpose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcac094a",
   "metadata": {},
   "source": [
    "#### Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "494c955c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5, 11],\n",
      "        [11, 25]])\n",
      "tensor([[ 5, 11],\n",
      "        [11, 25]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor2d.matmul(tensor2d.T))\n",
    "print(tensor2d @ tensor2d.T)  # Both are similar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e39ae62",
   "metadata": {},
   "source": [
    "# A.3 Seeing models as computation graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1176eb6",
   "metadata": {},
   "source": [
    "#### A logistic regression forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88443a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = tensor([1.]), dtype = torch.float32\n",
      "x1 = tensor([1.1000]), dtype = torch.float32\n",
      "w1 = tensor([2.2000]), dtype = torch.float32\n",
      "b = tensor([0.]), dtype = torch.float32\n",
      "z = tensor([2.4200]), dtype = torch.float32\n",
      "a = tensor([0.9183]), dtype = torch.float32\n",
      "loss = 0.0851878821849823, dtype = torch.float32\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F  # For activation functions\n",
    "\n",
    "y = torch.tensor([1.0])  # Target label\n",
    "print(f\"y = {y}, dtype = {y.dtype}\")\n",
    "\n",
    "x1 = torch.tensor([1.1])  # Input feature\n",
    "print(f\"x1 = {x1}, dtype = {x1.dtype}\")\n",
    "\n",
    "w1 = torch.tensor([2.2])  # Weight\n",
    "print(f\"w1 = {w1}, dtype = {w1.dtype}\")\n",
    "\n",
    "b = torch.tensor([0.0])  # Bias\n",
    "print(f\"b = {b}, dtype = {b.dtype}\")\n",
    "\n",
    "z = x1 * w1 + b  # Linear transformation (logits)\n",
    "print(f\"z = {z}, dtype = {z.dtype}\")\n",
    "\n",
    "a = torch.sigmoid(z)  # Sigmoid activation\n",
    "print(f\"a = {a}, dtype = {a.dtype}\")\n",
    "\n",
    "loss = F.binary_cross_entropy(a, y)  # Binary cross-entropy loss\n",
    "print(f\"loss = {loss}, dtype = {loss.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6241a178",
   "metadata": {},
   "source": [
    "# A.4 Automatic differentiation made easy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991a1e83",
   "metadata": {},
   "source": [
    "> **Note**: PyTorch will build a computation graph internally by default if one of its terminal nodes has the `requires_grad = True`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ab597a",
   "metadata": {},
   "source": [
    "#### Computing gradients via autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "232e8598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = tensor([1.])\n",
      "x1 = tensor([1.1000])\n",
      "w1 = tensor([2.2000], requires_grad=True)\n",
      "b = tensor([0.], requires_grad=True)\n",
      "z = tensor([2.4200], grad_fn=<AddBackward0>)\n",
      "a = tensor([0.9183], grad_fn=<SigmoidBackward0>)\n",
      "loss = 0.0851878821849823\n",
      "Gradient of loss w.r.t w1: (tensor([-0.0898]),)\n",
      "Gradient of loss w.r.t b: (tensor([-0.0817]),)\n",
      "Gradient of loss w.r.t w1 using backward(): tensor([-0.0898])\n",
      "Gradient of loss w.r.t b using backward(): tensor([-0.0817])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.autograd import (\n",
    "    grad,\n",
    ")  # Manual grad function helpful for experimentation, debugging, and understanding autograd mechanics.\n",
    "\n",
    "y = torch.tensor([1.0])  # Target label\n",
    "print(f\"y = {y}\")\n",
    "\n",
    "x1 = torch.tensor([1.1])  # Input feature\n",
    "print(f\"x1 = {x1}\")\n",
    "\n",
    "w1 = torch.tensor([2.2], requires_grad=True)  # Weight\n",
    "print(f\"w1 = {w1}\")\n",
    "\n",
    "b = torch.tensor([0.0], requires_grad=True)  # Bias\n",
    "print(f\"b = {b}\")\n",
    "\n",
    "z = x1 * w1 + b  # Linear transformation (logits)\n",
    "print(f\"z = {z}\")\n",
    "\n",
    "a = torch.sigmoid(z)  # Sigmoid activation\n",
    "print(f\"a = {a}\")\n",
    "\n",
    "loss = F.binary_cross_entropy(a, y)  # Binary cross-entropy loss\n",
    "print(f\"loss = {loss}\")\n",
    "\n",
    "grad_L_w1 = grad(loss, w1, retain_graph=True)  # Compute gradient of loss w.r.t w1\n",
    "print(f\"Gradient of loss w.r.t w1: {grad_L_w1}\")\n",
    "\n",
    "grad_L_b = grad(loss, b, retain_graph=True)  # Compute gradient of loss w.r.t b\n",
    "print(f\"Gradient of loss w.r.t b: {grad_L_b}\")\n",
    "\n",
    "loss.backward()  # Backpropagation to compute gradients\n",
    "print(f\"Gradient of loss w.r.t w1 using backward(): {w1.grad}\")\n",
    "print(f\"Gradient of loss w.r.t b using backward(): {b.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef15999d",
   "metadata": {},
   "source": [
    "# A.5 Implementing multilayer neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a247067b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(torch.nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs):\n",
    "        super().__init__()  # Initialize the base class\n",
    "        self.hidden_layer_1 = torch.nn.Linear(num_inputs, 30)\n",
    "        self.hidden_layer_2 = torch.nn.Linear(30, 20)\n",
    "        self.output_layer = torch.nn.Linear(20, num_outputs)\n",
    "        self.network = torch.nn.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c68054",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "build-a-large-language-model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
