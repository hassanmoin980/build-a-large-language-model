{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8c67c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca36dfc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.0+cu130\n",
      "13.0\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Check PyTorch version and CUDA availability\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993c3d86",
   "metadata": {},
   "source": [
    "# A.2 Understanding Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692c6cbe",
   "metadata": {},
   "source": [
    "## A.2.1 Scalars, vectores, matrices, and tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a45297d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-D tensor (scalar) from a Python integer: 1, having shape torch.Size([]), dimension = 0\n",
      "1-D tensor (vector) from a Python list: tensor([1, 2, 3]), having shape torch.Size([3]), dimension = 1\n",
      "2-D tensor from a nested Python list: tensor([[1, 2],\n",
      "        [3, 4]]), having shape torch.Size([2, 2]), dimension = 2\n",
      "3-D tensor from a nested Python list: tensor([[[1, 2],\n",
      "         [3, 4]],\n",
      "\n",
      "        [[5, 6],\n",
      "         [7, 8]]]), having shape torch.Size([2, 2, 2]), dimension = 3\n",
      "4-D tensor from a nested Python list: tensor([[[[1, 2, 9, 9],\n",
      "          [3, 4, 9, 9]],\n",
      "\n",
      "         [[5, 6, 9, 9],\n",
      "          [7, 8, 9, 9]],\n",
      "\n",
      "         [[5, 6, 9, 9],\n",
      "          [7, 8, 9, 9]]],\n",
      "\n",
      "\n",
      "        [[[1, 2, 9, 9],\n",
      "          [3, 4, 9, 9]],\n",
      "\n",
      "         [[5, 6, 9, 9],\n",
      "          [7, 8, 9, 9]],\n",
      "\n",
      "         [[5, 6, 9, 9],\n",
      "          [7, 8, 9, 9]]],\n",
      "\n",
      "\n",
      "        [[[1, 2, 9, 9],\n",
      "          [3, 4, 9, 9]],\n",
      "\n",
      "         [[5, 6, 9, 9],\n",
      "          [7, 8, 9, 9]],\n",
      "\n",
      "         [[5, 6, 9, 9],\n",
      "          [7, 8, 9, 9]]]]), having shape torch.Size([3, 3, 2, 4]), dimension = 4\n"
     ]
    }
   ],
   "source": [
    "# To create a 0-D, 1-D, 2-D, and 3-D tensor in PyTorch:\n",
    "tensor0d = torch.tensor(1)\n",
    "tensor1d = torch.tensor([1, 2, 3])\n",
    "tensor2d = torch.tensor([[1, 2], [3, 4]])\n",
    "tensor3d = torch.tensor([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n",
    "tensor4d = torch.tensor(\n",
    "    [\n",
    "        [\n",
    "            [[1, 2, 9, 9], [3, 4, 9, 9]],\n",
    "            [[5, 6, 9, 9], [7, 8, 9, 9]],\n",
    "            [[5, 6, 9, 9], [7, 8, 9, 9]],\n",
    "        ],\n",
    "        [\n",
    "            [[1, 2, 9, 9], [3, 4, 9, 9]],\n",
    "            [[5, 6, 9, 9], [7, 8, 9, 9]],\n",
    "            [[5, 6, 9, 9], [7, 8, 9, 9]],\n",
    "        ],\n",
    "        [\n",
    "            [[1, 2, 9, 9], [3, 4, 9, 9]],\n",
    "            [[5, 6, 9, 9], [7, 8, 9, 9]],\n",
    "            [[5, 6, 9, 9], [7, 8, 9, 9]],\n",
    "        ],\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"0-D tensor (scalar) from a Python integer: {tensor0d}, having shape {tensor0d.size()}, dimension = {tensor0d.dim()}\"\n",
    ")\n",
    "print(\n",
    "    f\"1-D tensor (vector) from a Python list: {tensor1d}, having shape {tensor1d.size()}, dimension = {tensor1d.dim()}\"\n",
    ")\n",
    "print(\n",
    "    f\"2-D tensor from a nested Python list: {tensor2d}, having shape {tensor2d.size()}, dimension = {tensor2d.dim()}\"\n",
    ")\n",
    "print(\n",
    "    f\"3-D tensor from a nested Python list: {tensor3d}, having shape {tensor3d.size()}, dimension = {tensor3d.dim()}\"\n",
    ")\n",
    "print(\n",
    "    f\"4-D tensor from a nested Python list: {tensor4d}, having shape {tensor4d.size()}, dimension = {tensor4d.dim()}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d6c704",
   "metadata": {},
   "source": [
    "## A.2.2 Tensor data types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169fb01b",
   "metadata": {},
   "source": [
    "#### By default, python *integers* create tensors of dtype torch.int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c89ca713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n",
      "torch.int64\n",
      "torch.int64\n",
      "torch.int64\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "print(tensor0d.dtype)\n",
    "print(tensor1d.dtype)\n",
    "print(tensor2d.dtype)\n",
    "print(tensor3d.dtype)\n",
    "print(tensor4d.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fe2db8",
   "metadata": {},
   "source": [
    "#### By default, python *floats* create tensors of dtype torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f557554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "tensor1d_float = torch.tensor([1.0, 2.0, 3.0])\n",
    "print(tensor1d_float.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3685b7",
   "metadata": {},
   "source": [
    "> **Note**: GPU architectures are optimized for 32-bit computations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d36b2fd",
   "metadata": {},
   "source": [
    "#### To change a tensor's dtype, use the .to() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ee0bd39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float64\n"
     ]
    }
   ],
   "source": [
    "tensor1d_float64 = tensor1d_float.to(torch.float64)\n",
    "print(tensor1d_float64.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2659b13b",
   "metadata": {},
   "source": [
    "## A.2.3 Common PyTorch tensor operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7035c3",
   "metadata": {},
   "source": [
    "#### Create new tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6d1bc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor2d = torch.tensor([[1, 2], [3, 4]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b68d941",
   "metadata": {},
   "source": [
    "#### Reshape tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8539222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "print(tensor2d)\n",
    "print(tensor2d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "107d47b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]])\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor2d.reshape(4, 1))\n",
    "print(tensor2d.view(4, 1))  # Both are similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5932ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 3],\n",
      "        [2, 4]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor2d.T)  # Transpose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcac094a",
   "metadata": {},
   "source": [
    "#### Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "494c955c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5, 11],\n",
      "        [11, 25]])\n",
      "tensor([[ 5, 11],\n",
      "        [11, 25]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor2d.matmul(tensor2d.T))\n",
    "print(tensor2d @ tensor2d.T)  # Both are similar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e39ae62",
   "metadata": {},
   "source": [
    "# A.3 Seeing models as computation graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1176eb6",
   "metadata": {},
   "source": [
    "#### A logistic regression forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88443a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = tensor([1.]), dtype = torch.float32\n",
      "x1 = tensor([1.1000]), dtype = torch.float32\n",
      "w1 = tensor([2.2000]), dtype = torch.float32\n",
      "b = tensor([0.]), dtype = torch.float32\n",
      "z = tensor([2.4200]), dtype = torch.float32\n",
      "a = tensor([0.9183]), dtype = torch.float32\n",
      "loss = 0.0851878821849823, dtype = torch.float32\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F  # For activation functions\n",
    "\n",
    "y = torch.tensor([1.0])  # Target label\n",
    "print(f\"y = {y}, dtype = {y.dtype}\")\n",
    "\n",
    "x1 = torch.tensor([1.1])  # Input feature\n",
    "print(f\"x1 = {x1}, dtype = {x1.dtype}\")\n",
    "\n",
    "w1 = torch.tensor([2.2])  # Weight\n",
    "print(f\"w1 = {w1}, dtype = {w1.dtype}\")\n",
    "\n",
    "b = torch.tensor([0.0])  # Bias\n",
    "print(f\"b = {b}, dtype = {b.dtype}\")\n",
    "\n",
    "z = x1 * w1 + b  # Linear transformation (logits)\n",
    "print(f\"z = {z}, dtype = {z.dtype}\")\n",
    "\n",
    "a = torch.sigmoid(z)  # Sigmoid activation\n",
    "print(f\"a = {a}, dtype = {a.dtype}\")\n",
    "\n",
    "loss = F.binary_cross_entropy(a, y)  # Binary cross-entropy loss\n",
    "print(f\"loss = {loss}, dtype = {loss.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6241a178",
   "metadata": {},
   "source": [
    "# A.4 Automatic differentiation made easy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991a1e83",
   "metadata": {},
   "source": [
    "> **Note**: PyTorch will build a computation graph internally by default if one of its terminal nodes has the `requires_grad = True`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ab597a",
   "metadata": {},
   "source": [
    "#### Computing gradients via autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "232e8598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = tensor([1.])\n",
      "x1 = tensor([1.1000])\n",
      "w1 = tensor([2.2000], requires_grad=True)\n",
      "b = tensor([0.], requires_grad=True)\n",
      "z = tensor([2.4200], grad_fn=<AddBackward0>)\n",
      "a = tensor([0.9183], grad_fn=<SigmoidBackward0>)\n",
      "loss = 0.0851878821849823\n",
      "Gradient of loss w.r.t w1: (tensor([-0.0898]),)\n",
      "Gradient of loss w.r.t b: (tensor([-0.0817]),)\n",
      "Gradient of loss w.r.t w1 using backward(): tensor([-0.0898])\n",
      "Gradient of loss w.r.t b using backward(): tensor([-0.0817])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.autograd import (\n",
    "    grad,\n",
    ")  # Manual grad function helpful for experimentation, debugging, and understanding autograd mechanics.\n",
    "\n",
    "y = torch.tensor([1.0])  # Target label\n",
    "print(f\"y = {y}\")\n",
    "\n",
    "x1 = torch.tensor([1.1])  # Input feature\n",
    "print(f\"x1 = {x1}\")\n",
    "\n",
    "w1 = torch.tensor([2.2], requires_grad=True)  # Weight\n",
    "print(f\"w1 = {w1}\")\n",
    "\n",
    "b = torch.tensor([0.0], requires_grad=True)  # Bias\n",
    "print(f\"b = {b}\")\n",
    "\n",
    "z = x1 * w1 + b  # Linear transformation (logits)\n",
    "print(f\"z = {z}\")\n",
    "\n",
    "a = torch.sigmoid(z)  # Sigmoid activation\n",
    "print(f\"a = {a}\")\n",
    "\n",
    "loss = F.binary_cross_entropy(a, y)  # Binary cross-entropy loss\n",
    "print(f\"loss = {loss}\")\n",
    "\n",
    "grad_L_w1 = grad(loss, w1, retain_graph=True)  # Compute gradient of loss w.r.t w1\n",
    "print(f\"Gradient of loss w.r.t w1: {grad_L_w1}\")\n",
    "\n",
    "grad_L_b = grad(loss, b, retain_graph=True)  # Compute gradient of loss w.r.t b\n",
    "print(f\"Gradient of loss w.r.t b: {grad_L_b}\")\n",
    "\n",
    "loss.backward()  # Backpropagation to compute gradients\n",
    "print(f\"Gradient of loss w.r.t w1 using backward(): {w1.grad}\")\n",
    "print(f\"Gradient of loss w.r.t b using backward(): {b.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef15999d",
   "metadata": {},
   "source": [
    "# A.5 Implementing multilayer neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a247067b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(torch.nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs):\n",
    "        super().__init__()  # Initialize the base class\n",
    "        self.hidden_layer_1 = torch.nn.Linear(num_inputs, 30)\n",
    "        self.hidden_layer_2 = torch.nn.Linear(30, 20)\n",
    "        self.output_layer = torch.nn.Linear(20, num_outputs)\n",
    "\n",
    "        self.network = torch.nn.Sequential(\n",
    "            self.hidden_layer_1,\n",
    "            torch.nn.ReLU(),\n",
    "            self.hidden_layer_2,\n",
    "            torch.nn.ReLU(),\n",
    "            self.output_layer,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.network(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = NeuralNetwork(50, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0285906e",
   "metadata": {},
   "source": [
    "> After instantiating `self.layers = Sequential(...)` in the `__init__` constructor, we just have to call the `self.layers` instead of calling each layer individually in the `NeuralNetwork`'s `forward`\n",
    "method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a3c68054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (hidden_layer_1): Linear(in_features=50, out_features=30, bias=True)\n",
      "  (hidden_layer_2): Linear(in_features=30, out_features=20, bias=True)\n",
      "  (output_layer): Linear(in_features=20, out_features=3, bias=True)\n",
      "  (network): Sequential(\n",
      "    (0): Linear(in_features=50, out_features=30, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=30, out_features=20, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=20, out_features=3, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e69908ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of trainable parameters in the model: 2213\n"
     ]
    }
   ],
   "source": [
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total number of trainable parameters in the model: {num_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf609a5d",
   "metadata": {},
   "source": [
    "> Note that each parameter for which `requires_grad=True` counts as a trainable parameter and will be updated during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c003f782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0577,  0.0047, -0.0702,  ...,  0.0222,  0.1260,  0.0865],\n",
      "        [ 0.0502,  0.0307,  0.0333,  ...,  0.0951,  0.1134, -0.0297],\n",
      "        [ 0.1077, -0.1108,  0.0122,  ...,  0.0108, -0.1049, -0.1063],\n",
      "        ...,\n",
      "        [-0.0787,  0.1259,  0.0803,  ...,  0.1218,  0.1303, -0.1351],\n",
      "        [ 0.1359,  0.0175, -0.0673,  ...,  0.0674,  0.0676,  0.1058],\n",
      "        [ 0.0790,  0.1343, -0.0293,  ...,  0.0344, -0.0971, -0.0509]],\n",
      "       requires_grad=True)\n",
      "torch.Size([30, 50])\n"
     ]
    }
   ],
   "source": [
    "print(model.network[0].weight)\n",
    "print(model.network[0].weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c62f20dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-0.1250,  0.0513,  0.0366,  0.0075,  0.0509,  0.0545, -0.0393,  0.0924,\n",
      "        -0.1412, -0.1232, -0.1063,  0.0081, -0.1249,  0.0101, -0.0019, -0.1298,\n",
      "         0.1388, -0.0330,  0.1017,  0.1247, -0.0554, -0.0417,  0.1388,  0.0159,\n",
      "         0.1215,  0.0385,  0.0769, -0.1224, -0.0279,  0.0991],\n",
      "       requires_grad=True)\n",
      "torch.Size([30])\n"
     ]
    }
   ],
   "source": [
    "print(model.network[0].bias)\n",
    "print(model.network[0].bias.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cb3d8e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2961, 0.5166, 0.2517, 0.6886, 0.0740, 0.8665, 0.1366, 0.1025, 0.1841,\n",
      "         0.7264, 0.3153, 0.6871, 0.0756, 0.1966, 0.3164, 0.4017, 0.1186, 0.8274,\n",
      "         0.3821, 0.6605, 0.8536, 0.5932, 0.6367, 0.9826, 0.2745, 0.6584, 0.2775,\n",
      "         0.8573, 0.8993, 0.0390, 0.9268, 0.7388, 0.7179, 0.7058, 0.9156, 0.4340,\n",
      "         0.0772, 0.3565, 0.1479, 0.5331, 0.4066, 0.2318, 0.4545, 0.9737, 0.4606,\n",
      "         0.5159, 0.4220, 0.5786, 0.9455, 0.8057]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "X = torch.rand((1, 50))\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7058ca38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1262,  0.1080, -0.1792]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "out = model(X)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f11c742",
   "metadata": {},
   "source": [
    "> when we use a model for inference (for instance, making predictions) rather than training, it is a best practice to use the `torch.no_grad()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "65e2180d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1262,  0.1080, -0.1792]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    out = model(X)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7cc4a785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3113, 0.3934, 0.2952]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    out = torch.softmax(model(X), dim=1)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9fa181",
   "metadata": {},
   "source": [
    "# A.6 Setting up efficient data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3290a94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "build-a-large-language-model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
